Adversarial_attacks paper with code  
1.DeepFool: a simple and accurate method to fool deep neural networks[(code)](https://github.com/LTS4/DeepFool)
2.Towards Evaluating the Robustness of Neural Networks[(code)](https://github.com/carlini/nn\_robust\_attacks)
3.ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models[(code)](https://github.com/huanzhang12/ZOO-Attack)
4.Simple Black-box Adversarial Attacks[(code)](https://github.com/cg563/simple-blackbox-attack)
5.Query-efficient Meta Attack to Deep Neural Networks[(code)](https://github.com/dydjw9/MetaAttack\_ICLR2020)  
6.Triangle Attack: A Query-efficient Decision-based Adversarial Attack[(code)](https://github.com/xiaosen-wang/TA)
7.explaining and harnessing adversarial examples&adversarial examples in the physical world[(code)](https://github.com/1Konny/FGSM)  
8.Foolbox Native: Fast adversarial attacks to benchmark the robustness of machine learning models in PyTorch, TensorFlow, and JAX[(code)](https://github.com/bethgelab/foolbox)  
9.EG-Booster: Explanation-Guided Booster of ML Evasion Attacks[(code)](https://github.com/EG-Booster/code)
10.Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models[(code)](https://github.com/greentfrapp/boundary-attack)
11.Distributional Smoothing with Virtual Adversarial Training[(code)](https://github.com/takerum/vat)
12.One pixel attack for fooling deep neural networks[(code)](https://github.com/Hyperparticle/one-pixel-attack-keras)
13.Fall of Giants: How popular text-based MLaaS fall against a simple evasion attack[(code)](https://github.com/pajola/ZeW)
14.Black-box Adversarial Attacks with Limited Queries and Information[(code)](https://github.com/labsix/limited-blackbox-attacks)
15.HopSkipJumpAttack: A Query-Efficient Decision-Based Attack[(code)](https://github.com/Jianbo-Lab/HSJA)
16.https://github.com/Trusted-AI/adversarial-robustness-toolbox
