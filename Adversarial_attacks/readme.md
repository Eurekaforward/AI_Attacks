Adversarial_attacks paper with code  
1.DeepFool: a simple and accurate method to fool deep neural networks[(code)](https://github.com/LTS4/DeepFool)
2.Towards Evaluating the Robustness of Neural Networks[(code)](https://github.com/AhmedSalem2/ML-Leaks)
[(code)](https://github.com/GeorgeTzannetos/ml-leaks-pytorch)  
3.ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models[(code)](https://github.com/inspire-group/privacy-vs-robustness)  
4.Simple Black-box Adversarial Attacks[(code)](https://github.com/inspire-group/membership-inference-evaluation)    
5.Query-efficient Meta Attack to Deep Neural Networks[(code)](https://github.com/jinyuan-jia/MemGuard)  
6.Triangle Attack: A Query-efficient Decision-based Adversarial Attack[(code)](https://github.com/hyhmia/BlindMI)  
7.explaining and harnessing adversarial examples[(code)](https://github.com/HongshengHu/source-inference-FL)  
8.Foolbox Native: Fast adversarial attacks to benchmark the robustness of machine learning models in PyTorch, TensorFlow, and JAX[(code)](https://github.com/DennisLiu2022/Membership-Inference-Attacks-by-Exploiting-Loss-Trajectory)  
9.EG-Booster: Explanation-Guided Booster of ML Evasion Attacks  
10.Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models
11.Distributional Smoothing with Virtual Adversarial Training
12.One pixel attack for fooling deep neural networks
13.Fall of Giants: How popular text-based MLaaS fall against a simple evasion attack
14.Black-box Adversarial Attacks with Limited Queries and Information
15.HopSkipJumpAttack: A Query-Efficient Decision-Based Attack
