1.Membership Inference Attack against Machine Learning Models[code](https://github.com/csong27/membership-inference)[code](https://github.com/yonsei-cysec/Membership_Inference_Attack)[code](https://github.com/spring-epfl/mia)  
2.ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models[code](https://github.com/AhmedSalem2/ML-Leaks)
[code](https://github.com/GeorgeTzannetos/ml-leaks-pytorch)  
3.Privacy Risks of Securing Machine Learning Models against Adversarial Examples[code](https://github.com/inspire-group/privacy-vs-robustness)  
4.Systematic Evaluation of Membership Inference Privacy Risks of Machine Learning Models[code](https://github.com/inspire-group/membership-inference-evaluation)    
5.{MemGuard}: Defending against Black-Box Membership Inference Attacks via Adversarial Examples[code](https://github.com/jinyuan-jia/MemGuard)  
6.Practical Blind Membership Inference Attack via Differential Comparisons[code](https://github.com/hyhmia/BlindMI)  
7.Source Inference Attacks in Federated Learning" for evaluating source inference attacks in federated learning[code](https://github.com/HongshengHu/source-inference-FL)  
8.Membership Inference Attacks by Exploiting Loss Trajectory[code](https://github.com/DennisLiu2022/Membership-Inference-Attacks-by-Exploiting-Loss-Trajectory)  
